{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\cleardoublepage\n",
    "\n",
    "# Results\n",
    "\n",
    "In this section various pipeline architectures are described and their performance on classifying the raw data are presented. More than 100 variants were tested during the pipeline development in total. Presenting all of them would neither be feasible nor helpful to the reader. Therefore, only variants that likely provide helpful insights to the reader are presented. The variants are presented in the order they were discovered, so the reader can follow how new insights led to new architectures and configurations. Each subsection presents a particular architecture and different configurations for each architecture are again  presented in sub-subsections. The last subsection of this section validates the best performing variant on the validation set.\n",
    "\n",
    "<!-- TODO  move to method?-->\n",
    "<!-- TODO add plot of confusion matrix with perfect fit-->\n",
    "The primary performance measure used is accuracy. Accuracy is defined as the proportion of correct classifications compared to all classifications with a score of 1 reflecting a perfect fit of the model. Accuracy can be misleading, if class sizes are very unequal, but this is not the case in the HAPT data set, so accuracy is a save measure. For a more detailed understanding of how well particular classes can be classified a confusion matrix is presented as well. The performance of each variant is tested on the test set. The best performing pipeline will then be tested again on the validation set to understand the pipeline's performance on new data.\n",
    "\n",
    "The models presented are non-deterministic as they are randomly initiated. To make this thesis entire reproducible a seed is set before running each variant. All variants use the default ETL and pre-processing configurations presented in the first subsection (@sec:default_etl_preprocessing_layers).\n",
    "\n",
    "## Default ETL and pre-processing layers {#sec:default_etl_preprocessing_layers}\n",
    "\n",
    "This subsection gives and overview of the default ETL and pre-processing layers applied to every implementation variant (see @tbl:default_etl_preprocessing_pipeline). See @lst:etl_cfg for the default configuration passed to the pipeline.\n",
    "\n",
    "\n",
    "Type | Layer\n",
    "--- | -----\n",
    "ETL | Loading and splitting\n",
    "ETL | Sequencing\n",
    "ETL | Sequence cleaning\n",
    "ETL | Separating input and output features\n",
    "ETL | Label selection\n",
    "ETL | Recoding output to binary features\n",
    "Pre-processing | Noise reduction in input\n",
    "Pre-processing | Separating bodily and gravitational acceleration\n",
    "Pre-processing | Normalizing input features\n",
    "\n",
    ": Default ETL and pre-processing layers used in every variant {#tbl:default_etl_preprocessing_pipeline}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "```{#lst:etl_cfg caption='Default configuration for ETL and pre-processing layers in all implemented pipeline variants.' .yaml}\n",
      "\n",
      "01_etl:\n",
      "  data_set_dir: 'data/HAPT Data Set'\n",
      "  download_url: 'https://archive.ics.uci.edu/ml/ machine-learning-databases/00341/HAPT%20Data%20Set.zip'\n",
      "  data_split:\n",
      "    train_participant_ids: [20,  6, 22, 18, 26, 27,  3, 11, 13, 30, 19, 12, 10, 17, 21,  4, 14, 24]\n",
      "    test_participant_ids: [16, 28,  2,  1, 23, 25]\n",
      "    validation_participant_ids: [ 7,  9, 15, 29,  8,  5]\n",
      "  selected_labels: [1,2,3,4,5,6]\n",
      "  channel_names_prior_preprocess: ['gyro-X', 'gyro-Y', 'gyro-Z', 'acc-X', 'acc-Y', 'acc-Z']\n",
      "  channl_names_post_preprocess: ['gyro-X', 'gyro-Y', 'gyro-Z', 'body-X', 'body-Y', 'body-Z', 'gravity-X', 'gravity-Y', 'gravity-Z']\n",
      "  sequence_length: 128\n",
      "  sequence_stepsize: 64\n",
      "  drop_columns: ['participant_id', 'experiment_id', 'time'] # the columns are loaded initially, because they are needed to sort and group data, but should not be used for modeling  \n",
      "  group_column: 'experiment_id' # data is sequenced within these groups\n",
      "  sample_rate: 50\n",
      "02_preprocessing:\n",
      "  sample_rate: 50\n",
      "  median_filter_kernel: 3\n",
      "  acc_columns_idx: [3,4,5] # indices of columns that contain the acceleration data\n",
      "\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import yaml\n",
    "import pprint\n",
    "yaml_config = \\\n",
    "\"\"\"\n",
    "01_etl:\n",
    "  data_set_dir: 'data/HAPT Data Set'\n",
    "  download_url: 'https://archive.ics.uci.edu/ml/ machine-learning-databases/00341/HAPT%20Data%20Set.zip'\n",
    "  data_split:\n",
    "    train_participant_ids: [20,  6, 22, 18, 26, 27,  3, 11, 13, 30, 19, 12, 10, 17, 21,  4, 14, 24]\n",
    "    test_participant_ids: [16, 28,  2,  1, 23, 25]\n",
    "    validation_participant_ids: [ 7,  9, 15, 29,  8,  5]\n",
    "  selected_labels: [1,2,3,4,5,6]\n",
    "  channel_names_prior_preprocess: ['gyro-X', 'gyro-Y', 'gyro-Z', 'acc-X', 'acc-Y', 'acc-Z']\n",
    "  channl_names_post_preprocess: ['gyro-X', 'gyro-Y', 'gyro-Z', 'body-X', 'body-Y', 'body-Z', 'gravity-X', 'gravity-Y', 'gravity-Z']\n",
    "  sequence_length: 128\n",
    "  sequence_stepsize: 64\n",
    "  drop_columns: ['participant_id', 'experiment_id', 'time'] # the columns are loaded initially, because they are needed to sort and group data, but should not be used for modeling  \n",
    "  group_column: 'experiment_id' # data is sequenced within these groups\n",
    "  sample_rate: 50\n",
    "02_preprocessing:\n",
    "  sample_rate: 50\n",
    "  median_filter_kernel: 3\n",
    "  acc_columns_idx: [3,4,5] # indices of columns that contain the acceleration data\n",
    "\"\"\"\n",
    "print(\n",
    "\"\"\"\n",
    "```{#lst:etl_cfg caption='Default configuration for ETL and pre-processing layers in all implemented pipeline variants.' .yaml}\n",
    "%s\n",
    "```\n",
    "\"\"\"\n",
    "% yaml_config)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": "masterthesis_tf_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
