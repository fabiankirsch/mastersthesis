
@article{fawaz_deep_2018,
	title = {Deep learning for time series classification: a review},
	url = {https://arxiv.org/abs/1809.04356v2},
	shorttitle = {Deep learning for time series classification},
	abstract = {Time Series Classification ({TSC}) is an important and challenging problem in
data mining. With the increase of time series data availability, hundreds of
{TSC} algorithms have been proposed. Among these methods, only a few have
considered Deep Neural Networks ({DNNs}) to perform this task. This is surprising
as deep learning has seen very successful applications in the last years. {DNNs}
have indeed revolutionized the field of computer vision especially with the
advent of novel deeper architectures such as Residual and Convolutional Neural
Networks. Apart from images, sequential data such as text and audio can also be
processed with {DNNs} to reach state-of-the-art performance for document
classification and speech recognition. In this article, we study the current
state-of-the-art performance of deep learning algorithms for {TSC} by presenting
an empirical study of the most recent {DNN} architectures for {TSC}. We give an
overview of the most successful deep learning applications in various time
series domains under a unified taxonomy of {DNNs} for {TSC}. We also provide an
open source deep learning framework to the {TSC} community where we implemented
each of the compared approaches and evaluated them on a univariate {TSC}
benchmark (the {UCR}/{UEA} archive) and 12 multivariate time series datasets. By
training 8,730 deep learning models on 97 time series datasets, we propose the
most exhaustive study of {DNNs} for {TSC} to date.},
	author = {Fawaz, Hassan Ismail and Forestier, Germain and Weber, Jonathan and Idoumghar, Lhassane and Muller, Pierre-Alain},
	urldate = {2019-02-18},
	date = {2018-09-12},
	langid = {english},
	file = {Full Text PDF:/home/fabian/Zotero/storage/R9PAMKMG/Fawaz et al. - 2018 - Deep learning for time series classification a re.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/89TLHESG/1809.html:text/html}
}

@article{reyes-ortiz_transition-aware_2016,
	title = {Transition-aware human activity recognition using smartphones},
	volume = {171},
	pages = {754--767},
	journaltitle = {Neurocomputing},
	author = {Reyes-Ortiz, Jorge-L. and Oneto, Luca and Samà, Albert and Parra, Xavier and Anguita, Davide},
	date = {2016},
	file = {Full Text:/home/fabian/Zotero/storage/VP2GJU7V/Reyes-Ortiz et al. - 2016 - Transition-aware human activity recognition using .pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/U2LE8YY2/S0925231215010930.html:text/html}
}

@book{shenoi_introduction_2005,
	title = {Introduction to Digital Signal Processing and Filter Design},
	isbn = {978-0-471-65638-8},
	abstract = {A practical and accessible guide to understanding digital signal {processingIntroduction} to Digital Signal Processing and Filter Design was developed and fine-tuned from the author's twenty-five years of experience teaching classes in digital signal processing. Following a step-by-step approach, students and professionals quickly master the fundamental concepts and applications of discrete-time signals and systems as well as the synthesis of these systems to meet specifications in the time and frequency domains. Striking the right balance between mathematical derivations and theory, the book features:* Discrete-time signals and systems* Linear difference equations* Solutions by recursive algorithms* Convolution* Time and frequency domain analysis* Discrete Fourier series* Design of {FIR} and {IIR} filters* Practical methods for hardware {implementationA} unique feature of this book is a complete chapter on the use of a {MATLAB}(r) tool, known as the {FDA} (Filter Design and Analysis) tool, to investigate the effect of finite word length and different formats of quantization, different realization structures, and different methods for filter design. This chapter contains material of practical importance that is not found in many books used in academic courses. It introduces students in digital signal processing to what they need to know to design digital systems using {DSP} chips currently available from industry.With its unique, classroom-tested approach, Introduction to Digital Signal Processing and Filter Design is the ideal text for students in electrical and electronic engineering, computer science, and applied mathematics, and an accessible introduction or refresher for engineers and scientists in the field.},
	pagetotal = {441},
	publisher = {John Wiley \& Sons},
	author = {Shenoi, B. A.},
	date = {2005-11-07},
	langid = {english},
	note = {Google-Books-{ID}: 37g8oUqaS\_AC},
	keywords = {Computers / Computer Engineering, Technology \& Engineering / Electrical}
}

@article{niedermeyer_electroencephalography:_2004,
	title = {Electroencephalography: basic principles, clinica l applications, and related},
	shorttitle = {Electroencephalography},
	pages = {193--207},
	journaltitle = {Electroencephalography: Basic Principles},
	author = {Niedermeyer, E. and {DA} {SILVA}, {FL}},
	date = {2004}
}

@inproceedings{de_jesus_rubio_ainsworth_2015,
	title = {Ainsworth, S.(2006). {DeFT}: A conceptual framework for considering learning with multiple representations. Learning and Instruction, 16 (3), 183-198. Bengio, Y., Courville, A., and Vincent, P.(2013). Representation learning: A review and new perspectives. Pattern Analysis and Machine Intelligence, {IEEE} Transactions on, 35 (8), 1798-1828.},
	volume = {105},
	shorttitle = {Ainsworth, S.(2006). {DeFT}},
	pages = {112},
	booktitle = {International Conference on Machine Learning},
	author = {de Jesus Rubio, J. and Angelov, P. and Pacheco, J.},
	date = {2015}
}

@inproceedings{de_jesus_rubio_ainsworth_2015-1,
	title = {Ainsworth, S.(2006). {DeFT}: A conceptual framework for considering learning with multiple representations. Learning and Instruction, 16 (3), 183-198. Bengio, Y., Courville, A., and Vincent, P.(2013). Representation learning: A review and new perspectives. Pattern Analysis and Machine Intelligence, {IEEE} Transactions on, 35 (8), 1798-1828.},
	volume = {105},
	shorttitle = {Ainsworth, S.(2006). {DeFT}},
	pages = {112},
	booktitle = {International Conference on Machine Learning},
	author = {de Jesus Rubio, J. and Angelov, P. and Pacheco, J.},
	date = {2015}
}

@incollection{simon_human_2017,
	title = {Human Problem Solving: The State of the Theory in 1970 1},
	shorttitle = {Human Problem Solving},
	pages = {131--151},
	booktitle = {Structural Learning (Volume 2)},
	publisher = {Routledge},
	author = {Simon, Herbert A. and Newell, Allen},
	date = {2017},
	file = {Snapshot:/home/fabian/Zotero/storage/9UDEDHUG/9781315222943-14.html:text/html}
}

@article{cook_15_2017,
	title = {15 Memory load and task interference: hidden usability issues in speech interfaces},
	shorttitle = {15 Memory load and task interference},
	journaltitle = {Engineering Psychology and Cognitive Ergonomics: Volume 1: Transportation Systems},
	author = {Cook, Malcolm J. and Cranmer, Charles and Finan, Robert and Sapeluk, Andy and Milton, Carol-Ann},
	date = {2017},
	file = {Snapshot:/home/fabian/Zotero/storage/7SCZ4MCQ/books.html:text/html}
}

@article{sheridan_humanrobot_2016,
	title = {Human–robot interaction: status and challenges},
	volume = {58},
	shorttitle = {Human–robot interaction},
	pages = {525--532},
	number = {4},
	journaltitle = {Human factors},
	author = {Sheridan, Thomas B.},
	date = {2016},
	file = {Full Text:/home/fabian/Zotero/storage/WQIX3BUJ/Sheridan - 2016 - Human–robot interaction status and challenges.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/V87PVTPV/0018720816644364.html:text/html}
}

@article{dixit_energy_2015,
	title = {Energy efficient dynamic bandwidth allocation for Ethernet passive optical networks: Overview, challenges, and solutions},
	volume = {18},
	shorttitle = {Energy efficient dynamic bandwidth allocation for Ethernet passive optical networks},
	pages = {169--179},
	journaltitle = {Optical Switching and Networking},
	author = {Dixit, Abhishek and Lannoo, Bart and Colle, Didier and Pickavet, Mario and Demeester, Piet},
	date = {2015},
	file = {Full Text:/home/fabian/Zotero/storage/FWKHVF7S/login.html:text/html;Snapshot:/home/fabian/Zotero/storage/LPDZUHBB/S157342771400040X.html:text/html}
}

@book{noble_forces_2017,
	title = {Forces of production: A social history of industrial automation},
	shorttitle = {Forces of production},
	publisher = {Routledge},
	author = {Noble, David},
	date = {2017},
	file = {Snapshot:/home/fabian/Zotero/storage/T9NJ92KX/9781351519618.html:text/html}
}

@book{lutz_world_2017,
	title = {World Population \& Human Capital in the Twenty-First Century: An Overview},
	shorttitle = {World Population \& Human Capital in the Twenty-First Century},
	publisher = {Oxford University Press},
	author = {Lutz, Wolfgang and Butz, William P. and Samir, {KC} ed},
	date = {2017},
	file = {Full Text:/home/fabian/Zotero/storage/ENE6MDC4/Lutz et al. - 2017 - World Population & Human Capital in the Twenty-Fir.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/CHQNTHVC/books.html:text/html}
}

@article{feenstra_next_2015,
	title = {The next generation of the Penn World Table},
	volume = {105},
	pages = {3150--82},
	number = {10},
	journaltitle = {American economic review},
	author = {Feenstra, Robert C. and Inklaar, Robert and Timmer, Marcel P.},
	date = {2015},
	file = {Full Text:/home/fabian/Zotero/storage/JHFHBKXH/Feenstra et al. - 2015 - The next generation of the Penn World Table.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/P4B3JTSJ/articles.html:text/html}
}

@article{peltzman_mortality_2009,
	title = {Mortality Inequality},
	volume = {23},
	issn = {0895-3309},
	url = {https://www.aeaweb.org/articles?id=10.1257/jep.23.4.175},
	doi = {10.1257/jep.23.4.175},
	abstract = {The paper describes how changes in the inequality of lifetimes have contributed to changes in the social distribution of welfare. I address the following questions: How can we measure inequality of lifetimes? How has this kind of inequality changed over time? How is this inequality related to increased longevity? How do these trends differ across and within countries? Unequal longevity was once a major source of social inequality, perhaps even more important in some sense than income inequality, for a long time. But over the last century, this inequality has declined drastically in high-income countries and is now comparatively trivial.},
	pages = {175--190},
	number = {4},
	journaltitle = {Journal of Economic Perspectives},
	author = {Peltzman, Sam},
	urldate = {2019-01-23},
	date = {2009-12},
	langid = {english},
	keywords = {and Other Normative Criteria and Measurement, and Their Distributions, Equity, Health Production, Inequality, Justice, Personal Income, Wealth},
	file = {Full Text PDF:/home/fabian/Zotero/storage/YVNWCR4X/Peltzman - 2009 - Mortality Inequality.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/BFEPAN3J/articles.html:text/html}
}

@article{bolt_m_2014,
	title = {The M addison P roject: collaborative research on historical national accounts},
	volume = {67},
	shorttitle = {The M addison P roject},
	pages = {627--651},
	number = {3},
	journaltitle = {The Economic History Review},
	author = {Bolt, Jutta and Van Zanden, Jan Luiten},
	date = {2014},
	file = {Full Text:/home/fabian/Zotero/storage/AVDKTP6C/login.html:text/html;Snapshot:/home/fabian/Zotero/storage/ZSVLFCZD/1468-0289.html:text/html}
}

@online{noauthor_povcalnet_nodate,
	title = {{PovcalNet}},
	url = {http://iresearch.worldbank.org/PovcalNet/povOnDemand.aspx},
	urldate = {2019-01-22},
	file = {PovcalNet:/home/fabian/Zotero/storage/FENC3CCE/povOnDemand.html:text/html}
}

@book{bourguinon_inequality_2009,
	title = {Inequality among world citizens: 1820-1992. The World Bank},
	shorttitle = {Inequality among world citizens},
	author = {Bourguinon, F. and Morrison, C.},
	date = {2009}
}

@online{noauthor_ending_2018,
	title = {Ending Poverty},
	url = {http://www.un.org/en/sections/issues-depth/poverty/},
	abstract = {While global poverty rates have been cut by more than half since 2000, one in ten people in developing regions still lives on less than {US}\$1.90 a day - the internationally agreed poverty line, and millions of others live on slightly more than this daily amount. Significant progress has been made in many countries within Eastern and Southeastern Asia, but up to 42\% of the population in Sub-Saharan Africa continues to live below the poverty line.},
	urldate = {2019-01-22},
	date = {2018-12-03},
	langid = {english},
	file = {Snapshot:/home/fabian/Zotero/storage/NZ7CWAEG/poverty.html:text/html}
}

@article{boybat_neuromorphic_2018,
	title = {Neuromorphic computing with multi-memristive synapses},
	volume = {9},
	rights = {2018 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-018-04933-y},
	doi = {10.1038/s41467-018-04933-y},
	abstract = {Memristive technology is a promising avenue towards realizing efficient non-von Neumann neuromorphic hardware. Boybat et al. proposes a multi-memristive synaptic architecture with a counter-based global arbitration scheme to address challenges associated with the non-ideal memristive device behavior.},
	pages = {2514},
	number = {1},
	journaltitle = {Nature Communications},
	author = {Boybat, Irem and Gallo, Manuel Le and Nandakumar, S. R. and Moraitis, Timoleon and Parnell, Thomas and Tuma, Tomas and Rajendran, Bipin and Leblebici, Yusuf and Sebastian, Abu and Eleftheriou, Evangelos},
	urldate = {2019-01-22},
	date = {2018-06-28},
	file = {Full Text PDF:/home/fabian/Zotero/storage/CNXUU324/Boybat et al. - 2018 - Neuromorphic computing with multi-memristive synap.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/YPULU7KM/s41467-018-04933-y.html:text/html}
}

@article{seth_theories_2006,
	title = {Theories and measures of consciousness: an extended framework},
	volume = {103},
	shorttitle = {Theories and measures of consciousness},
	pages = {10799--10804},
	number = {28},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Seth, Anil K. and Izhikevich, Eugene and Reeke, George N. and Edelman, Gerald M.},
	date = {2006},
	file = {Full Text:/home/fabian/Zotero/storage/8Q3WC68G/Seth et al. - 2006 - Theories and measures of consciousness an extende.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/C5EH8LXG/10799.html:text/html}
}

@article{baars_conscious_2002,
	title = {The conscious access hypothesis: origins and recent evidence},
	volume = {6},
	shorttitle = {The conscious access hypothesis},
	pages = {47--52},
	number = {1},
	journaltitle = {Trends in cognitive sciences},
	author = {Baars, Bernard J.},
	date = {2002},
	file = {Full Text:/home/fabian/Zotero/storage/7VT6VUUQ/Baars - 2002 - The conscious access hypothesis origins and recen.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/EUNHTSXG/S1364661300018192.html:text/html}
}

@article{huxley_hypothesis_1874,
	title = {On the hypothesis that animals are automata, and its history},
	volume = {1},
	journaltitle = {Collected essays},
	author = {Huxley, Thomas Henry},
	date = {1874}
}

@article{novack_origins_1965,
	title = {The origins of materialism},
	author = {Novack, George Edward},
	date = {1965},
	file = {Snapshot:/home/fabian/Zotero/storage/AN7DNC7Q/NOVTOO.html:text/html}
}

@book{koch_quest_2004,
	title = {The quest for consciousness: A neurobiological approach},
	shorttitle = {The quest for consciousness},
	publisher = {Roberts and Company Englewood, {CO}},
	author = {Koch, Christof},
	date = {2004}
}

@incollection{di_perri_measuring_2016,
	title = {Measuring consciousness through imaging},
	pages = {51--65},
	booktitle = {Brain Function and Responsiveness in Disorders of Consciousness},
	publisher = {Springer},
	author = {Di Perri, Carol and Annen, Jitka and Antonopoulos, Georgios and Amico, Enrico and Cavaliere, Carlo and Laureys, Steven},
	date = {2016},
	file = {Full Text:/home/fabian/Zotero/storage/Y9ZP8VAF/Di Perri et al. - 2016 - Measuring consciousness through imaging.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/M2MR7GUM/978-3-319-21425-2_5.html:text/html}
}

@article{delacour_neurobiology_1997,
	title = {Neurobiology of consciousness: an overview},
	volume = {85},
	issn = {0166-4328},
	url = {http://www.sciencedirect.com/science/article/pii/S0166432896001611},
	doi = {10.1016/S0166-4328(96)00161-1},
	shorttitle = {Neurobiology of consciousness},
	abstract = {The aim of this review is to connect the phenomenology of consciousness to its neurobiology. A survey of the recent literature revealed the following points. (1) Comprehensive descriptions of consciousness, of its subjective as well as of its objective aspects, are both possible and necessary for its scientific study. An intentionality-modeling structure (an unified and stable ego refers to objects or to itself in the framework of a stable, reproducible, predictable world) accounts for the main features. (2) The material basis of consciousness can be clarified without recourse to new properties of matter or to quantum physics. Current neurobiology appears to be able to handle the problem. In fact, the neurobiology of consciousness is already in progress, and has achieved substantial results. At the system level, its main sources of data are: the neurophysiology of sleep-wakefulness, brain imaging of mental representations, attention and working memory, the neuropsychology of frontal syndrome, and awareness-unawareness dissociations in global amnesia and different forms of agnosia. At an intermediate level of organization, the mechanisms of consciousness may be the formation of a certain kind of neural assembly. (3) Further research may focus on neuropsychology and neurophysiology of object perception and recognition as a natural model of intentionality, perception of time, body schema, interhemispheric communications, `voluntary' acts and mental images. The synthetic and dynamic views provided by brain imaging may be decisive for discovering the neural correlates of the integrative aspects of consciousness. (4) The neurobiological approach may, beyond the finding of cellular and molecular mechanisms, improve the general concepts of consciousness, overcome their antinomies and, against epiphenomenalism, definitely establish the reality of consciousness.},
	pages = {127--141},
	number = {2},
	journaltitle = {Behavioural Brain Research},
	shortjournal = {Behavioural Brain Research},
	author = {Delacour, Jean},
	urldate = {2019-01-21},
	date = {1997-05-01},
	keywords = {Awareness-unawareness dissociation, Blindsight, Consciousness, Declarative memory, Frontal activation, Intentionality, Neural assembly, Neurophysiology of sleep-wakefulness, Self, Thalamus, World},
	file = {ScienceDirect Snapshot:/home/fabian/Zotero/storage/JZZB5BD8/S0166432896001611.html:text/html}
}

@online{noauthor_qualia_nodate,
	title = {qualia - Wiktionary},
	url = {https://en.wiktionary.org/wiki/qualia},
	urldate = {2019-01-21},
	file = {qualia - Wiktionary:/home/fabian/Zotero/storage/UMBKZIBJ/qualia.html:text/html}
}

@book{burns_scientific_2001,
	title = {The scientific revolution: an encyclopedia},
	shorttitle = {The scientific revolution},
	publisher = {{ABC}-{CLIO}},
	author = {Burns, William E.},
	date = {2001},
	file = {Snapshot:/home/fabian/Zotero/storage/YXX5AGHP/books.html:text/html}
}

@article{tononi_integrated_2016,
	title = {Integrated information theory: from consciousness to its physical substrate},
	volume = {17},
	shorttitle = {Integrated information theory},
	pages = {450},
	number = {7},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Tononi, Giulio and Boly, Melanie and Massimini, Marcello and Koch, Christof},
	date = {2016},
	file = {Full Text:/home/fabian/Zotero/storage/KSNQURNZ/Tononi et al. - 2016 - Integrated information theory from consciousness .pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/68KIXX5M/nrn.2016.html:text/html}
}

@article{tononi_information_2004,
	title = {An information integration theory of consciousness},
	volume = {5},
	pages = {42},
	number = {1},
	journaltitle = {{BMC} neuroscience},
	author = {Tononi, Giulio},
	date = {2004},
	file = {Full Text:/home/fabian/Zotero/storage/4G7KSQIW/1471-2202-5-42.html:text/html}
}

@article{crick_framework_2003,
	title = {A framework for consciousness},
	volume = {6},
	pages = {119},
	number = {2},
	journaltitle = {Nature neuroscience},
	author = {Crick, Francis and Koch, Christof},
	date = {2003},
	file = {Full Text:/home/fabian/Zotero/storage/PLSGK5LM/Crick and Koch - 2003 - A framework for consciousness.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/BQY8WDQ7/nn0203-119.html:text/html}
}

@article{dehaene_conscious_2006,
	title = {Conscious, preconscious, and subliminal processing: a testable taxonomy},
	volume = {10},
	shorttitle = {Conscious, preconscious, and subliminal processing},
	pages = {204--211},
	number = {5},
	journaltitle = {Trends in cognitive sciences},
	author = {Dehaene, Stanislas and Changeux, Jean-Pierre and Naccache, Lionel and Sackur, Jérôme and Sergent, Claire},
	date = {2006},
	file = {Full Text:/home/fabian/Zotero/storage/EBTPECIJ/Dehaene et al. - 2006 - Conscious, preconscious, and subliminal processing.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/PT4L29CK/S1364661306000799.html:text/html}
}

@article{parvizi_consciousness_2001,
	title = {Consciousness and the brainstem},
	volume = {79},
	pages = {135--160},
	number = {1},
	journaltitle = {Cognition},
	author = {Parvizi, Josef and Damasio, Antonio},
	date = {2001},
	file = {Full Text:/home/fabian/Zotero/storage/QA3NYDWG/Parvizi and Damasio - 2001 - Consciousness and the brainstem.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/MVVHQQ6A/S001002770000127X.html:text/html}
}

@book{farthing_psychology_1992,
	title = {The psychology of consciousness.},
	publisher = {Prentice-Hall, Inc},
	author = {Farthing, G. William},
	date = {1992},
	file = {Snapshot:/home/fabian/Zotero/storage/YJTI5BIS/1992-97049-000.html:text/html}
}

@article{bostrom_how_1998,
	title = {How long before superintelligence?},
	author = {Bostrom, Nick},
	date = {1998},
	file = {Snapshot:/home/fabian/Zotero/storage/994KPTVC/BOSHLB.html:text/html}
}

@article{chalmers_facing_1995,
	title = {Facing up to the problem of consciousness},
	volume = {2},
	pages = {200--219},
	number = {3},
	journaltitle = {Journal of consciousness studies},
	author = {Chalmers, David J.},
	date = {1995},
	file = {Full Text:/home/fabian/Zotero/storage/Z7WSLFHY/consciousness.html:text/html;Snapshot:/home/fabian/Zotero/storage/EIPSB7ZB/653.html:text/html}
}

@article{legg_universal_2007,
	title = {Universal intelligence: A definition of machine intelligence},
	volume = {17},
	shorttitle = {Universal intelligence},
	pages = {391--444},
	number = {4},
	journaltitle = {Minds and Machines},
	author = {Legg, Shane and Hutter, Marcus},
	date = {2007},
	file = {Full Text:/home/fabian/Zotero/storage/6N6TBFDE/Legg and Hutter - 2007 - Universal intelligence A definition of machine in.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/EVKFUMJQ/s11023-007-9079-x.html:text/html}
}

@article{gray_neurobiology_2004,
	title = {Neurobiology of intelligence: science and ethics},
	volume = {5},
	shorttitle = {Neurobiology of intelligence},
	pages = {471},
	number = {6},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Gray, Jeremy R. and Thompson, Paul M.},
	date = {2004},
	file = {Full Text:/home/fabian/Zotero/storage/NP4W8QE7/Gray and Thompson - 2004 - Neurobiology of intelligence science and ethics.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/BQ2DKDH3/nrn1405.html:text/html}
}

@book{mackintosh_iq_2011,
	title = {{IQ} and human intelligence},
	publisher = {Oxford University Press},
	author = {Mackintosh, Nicholas and Mackintosh, Nicholas John},
	date = {2011},
	file = {Snapshot:/home/fabian/Zotero/storage/UN36LP88/books.html:text/html}
}

@book{deary_intelligence:_2001,
	title = {Intelligence: A very short introduction},
	shorttitle = {Intelligence},
	publisher = {{OUP} Oxford},
	author = {Deary, Ian J.},
	date = {2001},
	file = {Snapshot:/home/fabian/Zotero/storage/TNP8Z8VI/books.html:text/html}
}

@article{reader_evolution_2011,
	title = {The evolution of primate general and cultural intelligence},
	volume = {366},
	pages = {1017--1027},
	number = {1567},
	journaltitle = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
	author = {Reader, Simon M. and Hager, Yfke and Laland, Kevin N.},
	date = {2011},
	file = {Full Text:/home/fabian/Zotero/storage/MZFYVGTR/Reader et al. - 2011 - The evolution of primate general and cultural inte.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/X7PFLHST/rstb.2010.html:text/html}
}

@article{turing_computable_1937,
	title = {On Computable Numbers, with an Application to the Entscheidungsproblem},
	volume = {s2-42},
	rights = {© 1937 London Mathematical Society},
	issn = {1460-244X},
	url = {https://londmathsoc.onlinelibrary.wiley.com/doi/abs/10.1112/plms/s2-42.1.230},
	doi = {10.1112/plms/s2-42.1.230},
	pages = {230--265},
	number = {1},
	journaltitle = {Proceedings of the London Mathematical Society},
	author = {Turing, A. M.},
	urldate = {2019-01-15},
	date = {1937},
	langid = {english},
	file = {Snapshot:/home/fabian/Zotero/storage/SR6PBDDW/s2-42.1.html:text/html}
}

@article{von_neumann_first_1945,
	title = {First Draft of a Report on the {EDVAC}, 30 June 1945},
	journaltitle = {Contract No W-670-{ORD}-492, Moore School of Electrical Engineering, University of Pennsylvania, Philadelphia. Google Scholar},
	author = {Von Neumann, John},
	date = {1945}
}

@article{sebastian_tutorial:_2018,
	title = {Tutorial: Brain-inspired computing using phase-change memory                     devices},
	volume = {124},
	issn = {0021-8979},
	url = {https://aip.scitation.org/doi/10.1063/1.5042413},
	doi = {10.1063/1.5042413},
	shorttitle = {Tutorial},
	abstract = {There is a significant need to build efficient non-von Neumann computing systems                     for highly data-centric artificial intelligence related applications.                     Brain-inspired computing is one such approach that shows significant promise.                     Memory is expected to play a key role in this form of computing and, in                     particular, phase-change memory ({PCM}), arguably the most advanced emerging                     non-volatile memory technology. Given a lack of comprehensive understanding of                     the working principles of the brain, brain-inspired computing is likely to be                     realized in multiple levels of inspiration. In the first level of inspiration,                     the idea would be to build computing units where memory and processing co-exist                     in some form. Computational memory is an example where the physical attributes                     and the state dynamics of memory devices are exploited to perform certain                     computational tasks in the memory itself with very high areal and energy                     efficiency. In a second level of brain-inspired computing using {PCM} devices, one                     could design a co-processor comprising multiple cross-bar arrays of {PCM} devices                     to accelerate the training of deep neural networks. {PCM} technology could also                     play a key role in the space of specialized computing substrates for spiking                     neural networks, and this can be viewed as the third level of brain-inspired                     computing using these devices.},
	pages = {111101},
	number = {11},
	journaltitle = {Journal of Applied Physics},
	shortjournal = {Journal of Applied Physics},
	author = {Sebastian, Abu and Le Gallo, Manuel and Burr, Geoffrey W. and Kim, Sangbum and {BrightSky}, Matthew and Eleftheriou, Evangelos},
	urldate = {2019-01-15},
	date = {2018-09-18},
	file = {Full Text PDF:/home/fabian/Zotero/storage/PMBXH59G/Sebastian et al. - 2018 - Tutorial Brain-inspired computing using phase-cha.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/RXXHD5IS/1.html:text/html}
}

@book{miranda_studia_2007,
	title = {Studia archaeologica},
	isbn = {978-88-8265-433-7},
	abstract = {This is a study of the water-raising wheels of western Syria from the aspects of sources, terminology, typology, origin, history, technology and architecture, and gives a survey of these installations, discussing their present state of conservation. By making use of historical, architectural and iconographical material, the study shows that Syrian water-wheels constitutes a particular type of water-architecture, which successfully combines the functional with the aesthetic and displays sophisticated forms of construction. These devices are visually impressive, present a variety of shapes and are of great historical, environmental and iconographical importance, being of extraordinarily accurate and detailed design. An attempt is made to present evidence of their ancient origin, and to gain an understanding of how their design evolved over time, the reasons for their significance and uniqueness, and for their great concentration in Syria.},
	pagetotal = {384},
	publisher = {L'{ERMA} di {BRETSCHNEIDER}},
	author = {Miranda, Adriana de},
	date = {2007},
	langid = {english},
	note = {Google-Books-{ID}: D6rsB59RRZkC},
	keywords = {History / Ancient / General, History / Middle East / General, Science / History, Social Science / Archaeology, Technology \& Engineering / History}
}

@book{hollnagel_joint_2005,
	title = {Joint Cognitive Systems: Foundations of Cognitive Systems Engineering},
	isbn = {978-1-4200-3819-4},
	shorttitle = {Joint Cognitive Systems},
	abstract = {Nothing has been more prolific over the past century than human/machine interaction. Automobiles, telephones, computers, manufacturing machines, robots, office equipment, machines large and small; all affect the very essence of our daily lives. However, this interaction has not always been efficient or easy and has at times turned fairly hazardous. Cognitive Systems Engineering ({CSE}) seeks to improve this situation by the careful study of human/machine interaction as the meaningful behavior of a unified system.Written by pioneers in the development of {CSE}, Joint Cognitive Systems: Foundations of Cognitive Systems Engineering offers a principled approach to studying human work with complex technology. The authors use a top-down, functional approach and emphasize a proactive (coping) perspective on work that overcomes the limitations of the structural human information processing view. They describe a conceptual framework for analysis with concrete theories and methods for joint system modeling that can be applied across the spectrum of single human/machine systems, social/technical systems, and whole organizations. The book explores both current and potential applications of {CSE} illustrated by examples.Understanding the complexities and functions of the human/machine interaction is critical to designing safe, highly functional, and efficient technological systems. This is a critical reference for students, designers, and engineers in a wide variety of disciplines.},
	pagetotal = {236},
	publisher = {{CRC} Press},
	author = {Hollnagel, Erik and Woods, David D.},
	date = {2005-02-28},
	langid = {english},
	keywords = {Computers / Computer Engineering, Computers / General, Technology \& Engineering / Engineering (General), Technology \& Engineering / Industrial Engineering, Technology \& Engineering / Industrial Health \& Safety}
}

@book{hawkins_intelligence_2007,
	title = {On Intelligence},
	isbn = {978-1-4299-0045-4},
	abstract = {From the inventor of the {PalmPilot} comes a new and compelling theory of intelligence, brain function, and the future of intelligent {machinesJeff} Hawkins, the man who created the {PalmPilot}, Treo smart phone, and other handheld devices, has reshaped our relationship to computers. Now he stands ready to revolutionize both neuroscience and computing in one stroke, with a new understanding of intelligence itself.Hawkins develops a powerful theory of how the human brain works, explaining why computers are not intelligent and how, based on this new theory, we can finally build intelligent machines.The brain is not a computer, but a memory system that stores experiences in a way that reflects the true structure of the world, remembering sequences of events and their nested relationships and making predictions based on those memories. It is this memory-prediction system that forms the basis of intelligence, perception, creativity, and even consciousness.In an engaging style that will captivate audiences from the merely curious to the professional scientist, Hawkins shows how a clear understanding of how the brain works will make it possible for us to build intelligent machines, in silicon, that will exceed our human ability in surprising ways.Written with acclaimed science writer Sandra Blakeslee, On Intelligence promises to completely transfigure the possibilities of the technology age. It is a landmark book in its scope and clarity.},
	pagetotal = {278},
	publisher = {Macmillan},
	author = {Hawkins, Jeff and Blakeslee, Sandra},
	date = {2007-04-01},
	langid = {english},
	note = {Google-Books-{ID}: Qg2dmntfxmQC},
	keywords = {Computers / Intelligence ({AI}) \& Semantics, Science / Life Sciences / Neuroscience},
	file = {Jeff Hawkins - On Intelligence.pdf:/home/fabian/Zotero/storage/ZDW7UTAF/Jeff Hawkins - On Intelligence.pdf:application/pdf}
}

@article{van_hees_separating_2013,
	title = {Separating Movement and Gravity Components in an Acceleration Signal and Implications for the Assessment of Human Daily Physical Activity},
	volume = {8},
	issn = {1932-6203},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3634007/},
	doi = {10.1371/journal.pone.0061691},
	abstract = {Introduction
Human body acceleration is often used as an indicator of daily physical activity in epidemiological research. Raw acceleration signals contain three basic components: movement, gravity, and noise. Separation of these becomes increasingly difficult during rotational movements. We aimed to evaluate five different methods (metrics) of processing acceleration signals on their ability to remove the gravitational component of acceleration during standardised mechanical movements and the implications for human daily physical activity assessment.

Methods
An industrial robot rotated accelerometers in the vertical plane. Radius, frequency, and angular range of motion were systematically varied. Three metrics (Euclidian norm minus one [{ENMO}], Euclidian norm of the high-pass filtered signals [{HFEN}], and {HFEN} plus Euclidean norm of low-pass filtered signals minus 1 g [{HFEN}+]) were derived for each experimental condition and compared against the reference acceleration (forward kinematics) of the robot arm. We then compared metrics derived from human acceleration signals from the wrist and hip in 97 adults (22–65 yr), and wrist in 63 women (20–35 yr) in whom daily activity-related energy expenditure ({PAEE}) was available.

Results
In the robot experiment, {HFEN}+ had lowest error during (vertical plane) rotations at an oscillating frequency higher than the filter cut-off frequency while for lower frequencies {ENMO} performed better. In the human experiments, metrics {HFEN} and {ENMO} on hip were most discrepant (within- and between-individual explained variance of 0.90 and 0.46, respectively). {ENMO}, {HFEN} and {HFEN}+ explained 34\%, 30\% and 36\% of the variance in daily {PAEE}, respectively, compared to 26\% for a metric which did not attempt to remove the gravitational component (metric {EN}).

Conclusion
In conclusion, none of the metrics as evaluated systematically outperformed all other metrics across a wide range of standardised kinematic conditions. However, choice of metric explains different degrees of variance in daily human physical activity.},
	number = {4},
	journaltitle = {{PLoS} {ONE}},
	shortjournal = {{PLoS} One},
	author = {van Hees, Vincent T. and Gorzelniak, Lukas and Dean León, Emmanuel Carlos and Eder, Martin and Pias, Marcelo and Taherian, Salman and Ekelund, Ulf and Renström, Frida and Franks, Paul W. and Horsch, Alexander and Brage, Søren},
	urldate = {2019-02-22},
	date = {2013-04-23},
	pmid = {23626718},
	pmcid = {PMC3634007},
	file = {PubMed Central Full Text PDF:/home/fabian/Zotero/storage/5RC3K4HD/van Hees et al. - 2013 - Separating Movement and Gravity Components in an A.pdf:application/pdf}
}

@article{wilson_marginal_2017,
	title = {The Marginal Value of Adaptive Gradient Methods in Machine Learning},
	url = {http://arxiv.org/abs/1705.08292},
	abstract = {Adaptive optimization methods, which perform local optimization with a metric constructed from the history of iterates, are becoming increasingly popular for training deep neural networks. Examples include {AdaGrad}, {RMSProp}, and Adam. We show that for simple overparameterized problems, adaptive methods often find drastically different solutions than gradient descent ({GD}) or stochastic gradient descent ({SGD}). We construct an illustrative binary classification problem where the data is linearly separable, {GD} and {SGD} achieve zero test error, and {AdaGrad}, Adam, and {RMSProp} attain test errors arbitrarily close to half. We additionally study the empirical generalization capability of adaptive methods on several state-of-the-art deep learning models. We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than {SGD}, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.},
	journaltitle = {{arXiv}:1705.08292 [cs, stat]},
	author = {Wilson, Ashia C. and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nathan and Recht, Benjamin},
	urldate = {2019-02-25},
	date = {2017-05-23},
	eprinttype = {arxiv},
	eprint = {1705.08292},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1705.08292 PDF:/home/fabian/Zotero/storage/88TDS2AV/Wilson et al. - 2017 - The Marginal Value of Adaptive Gradient Methods in.pdf:application/pdf;arXiv.org Snapshot:/home/fabian/Zotero/storage/X6D2QAU5/1705.html:text/html}
}

@article{andrychowicz_learning_2016,
	title = {Learning to learn by gradient descent by gradient descent},
	url = {http://arxiv.org/abs/1606.04474},
	abstract = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by {LSTMs}, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},
	journaltitle = {{arXiv}:1606.04474 [cs]},
	author = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and Shillingford, Brendan and de Freitas, Nando},
	urldate = {2019-03-01},
	date = {2016-06-14},
	eprinttype = {arxiv},
	eprint = {1606.04474},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Machine Learning},
	file = {arXiv\:1606.04474 PDF:/home/fabian/Zotero/storage/ISD7K8WZ/Andrychowicz et al. - 2016 - Learning to learn by gradient descent by gradient .pdf:application/pdf;arXiv.org Snapshot:/home/fabian/Zotero/storage/IN328JRF/1606.html:text/html}
}

@software{noauthor_open_2019,
	title = {An Open Source Machine Learning Framework for Everyone: tensorflow/tensorflow},
	rights = {Apache-2.0},
	url = {https://github.com/tensorflow/tensorflow},
	shorttitle = {An Open Source Machine Learning Framework for Everyone},
	publisher = {tensorflow},
	urldate = {2019-03-27},
	date = {2019-03-27},
	note = {original-date: 2015-11-07T01:19:20Z}
}

@online{iea_definition_2019,
	title = {Definition and Domains of Ergonomics {\textbar} {IEA} Website},
	url = {https://www.iea.cc/whats/index.html},
	shorttitle = {definition human factors},
	author = {{IEA}},
	urldate = {2019-03-28},
	date = {2019},
	file = {Definition and Domains of Ergonomics | IEA Website:/home/fabian/Zotero/storage/T4339AA5/index.html:text/html}
}

@incollection{salas_human_2010,
	title = {Human factors in aviation: an overview},
	shorttitle = {Human factors in aviation},
	pages = {3--19},
	booktitle = {Human factors in aviation},
	publisher = {Elsevier},
	author = {Salas, Eduardo and Maurino, Dan and Curtis, Michael},
	date = {2010},
	file = {Full Text:/home/fabian/Zotero/storage/SIQBYYMY/Salas et al. - 2010 - Human factors in aviation an overview.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/HTH3U9F2/B9780123745187000018.html:text/html}
}

@book{proctor_human_2018,
	title = {Human factors in simple and complex systems},
	publisher = {{CRC} press},
	author = {Proctor, Robert W. and Van Zandt, Trisha},
	date = {2018},
	file = {Snapshot:/home/fabian/Zotero/storage/XPUIS264/9781482229578.html:text/html}
}

@article{chapanis_applied_1949,
	title = {Applied experimental psychology: Human factors in engineering design.},
	shorttitle = {Applied experimental psychology},
	author = {Chapanis, Alphonse and Garner, Wendell R. and Morgan, Clifford T.},
	date = {1949},
	file = {Snapshot:/home/fabian/Zotero/storage/2DX8I5MX/2006-09481-000.html:text/html}
}

@article{muller_machine_2008,
	title = {Machine learning for real-time single-trial {EEG}-analysis: from brain–computer interfacing to mental state monitoring},
	volume = {167},
	shorttitle = {Machine learning for real-time single-trial {EEG}-analysis},
	pages = {82--90},
	number = {1},
	journaltitle = {Journal of neuroscience methods},
	author = {Müller, Klaus-Robert and Tangermann, Michael and Dornhege, Guido and Krauledat, Matthias and Curio, Gabriel and Blankertz, Benjamin},
	date = {2008},
	file = {Full Text:/home/fabian/Zotero/storage/5EL9FBGS/Müller et al. - 2008 - Machine learning for real-time single-trial EEG-an.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/8FBHDC6U/S0165027007004657.html:text/html}
}

@article{rani_empirical_2006,
	title = {An empirical study of machine learning techniques for affect recognition in human–robot interaction},
	volume = {9},
	pages = {58--69},
	number = {1},
	journaltitle = {Pattern Analysis and Applications},
	author = {Rani, Pramila and Liu, Changchun and Sarkar, Nilanjan and Vanman, Eric},
	date = {2006},
	file = {Snapshot:/home/fabian/Zotero/storage/59CQ65U8/s10044-006-0025-y.html:text/html}
}

@inproceedings{rehg_digiteyes:_1994,
	title = {Digiteyes: Vision-based hand tracking for human-computer interaction},
	shorttitle = {Digiteyes},
	pages = {16--22},
	booktitle = {Proceedings of 1994 {IEEE} Workshop on Motion of Non-rigid and Articulated Objects},
	publisher = {{IEEE}},
	author = {Rehg, James M. and Kanade, Takeo},
	date = {1994},
	file = {Full Text:/home/fabian/Zotero/storage/M975HJJS/Rehg and Kanade - 1994 - Digiteyes Vision-based hand tracking for human-co.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/BSAC6MNZ/346260.html:text/html}
}

@article{rautaray_vision_2015,
	title = {Vision based hand gesture recognition for human computer interaction: a survey},
	volume = {43},
	shorttitle = {Vision based hand gesture recognition for human computer interaction},
	pages = {1--54},
	number = {1},
	journaltitle = {Artificial Intelligence Review},
	author = {Rautaray, Siddharth S. and Agrawal, Anupam},
	date = {2015},
	file = {Full Text:/home/fabian/Zotero/storage/MKTZJZUV/Rautaray and Agrawal - 2015 - Vision based hand gesture recognition for human co.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/FWU34HLM/s10462-012-9356-9.html:text/html}
}

@online{noauthor_pdf_nodate,
	title = {({PDF}) Team {PhyPA}: Brain-computer interfacing for everyday human-computer interaction},
	url = {https://www.researchgate.net/publication/317752429_Team_PhyPA_Brain-computer_interfacing_for_everyday_human-computer_interaction},
	shorttitle = {({PDF}) Team {PhyPA}},
	abstract = {{PDF} {\textbar} Brain-computer interfaces can provide an input channel from humans to computers that depends only on brain activity, bypassing traditional means of communication and interaction. This input channel can be used to send explicit commands, but also to provide implicit input to...},
	titleaddon = {{ResearchGate}},
	urldate = {2019-03-28},
	langid = {english},
	doi = {http://dx.doi.org/10.3311/PPee.10435},
	file = {Full Text:/home/fabian/Zotero/storage/THGCKZRZ/(PDF) Team PhyPA Brain-computer interfacing for e.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/45U5UWH9/317752429_Team_PhyPA_Brain-computer_interfacing_for_everyday_human-computer_interaction.html:text/html}
}

@book{tufte_envisioning_1990,
	title = {Envisioning information},
	volume = {126},
	publisher = {Graphics press Cheshire, {CT}},
	author = {Tufte, Edward R. and Goeler, Nora Hillman and Benson, Richard},
	date = {1990},
	file = {Snapshot:/home/fabian/Zotero/storage/76SD4PAU/13rRUwciPeY.html:text/html}
}

@book{suchman_plans_1987,
	title = {Plans and situated actions: The problem of human-machine communication},
	shorttitle = {Plans and situated actions},
	publisher = {Cambridge university press},
	author = {Suchman, Lucy A.},
	date = {1987},
	file = {Full Text:/home/fabian/Zotero/storage/9LJPPCHE/Suchman - 1987 - Plans and situated actions The problem of human-m.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/X4SDP6PC/books.html:text/html}
}

@patent{conigliaro_seat_1989,
	title = {Seat belt indicator system},
	url = {https://patents.google.com/patent/US4849733A/en},
	holder = {Conigliaro Thomas S, Coniliaro Samuel J},
	abstract = {An electrical system for providing an audible or visible warning and interior and exterior visible displays indicating whether the occupants of a motor vehicle have fastened their seat belts, in compliance with legal requirements and/or the will of the driver. The system involves a plurality of circuits each of which is associated with a driver's seat sensor switch, with a seat belt latch and with an interior display panel, and at least some of which are also associated with exterior display lights. Each said circuit has a seat belt latch for closing or opening said circuit, when the driver's seat sensor switch is closed, to change the condition of a light at a corresponding position on the interior display panel and, for at least the front seat belts, to change the condition of a corresponding exterior display light. The system also includes a warning circuit including an audible or visible warning signal which is activated when the driver's seat sensor switch is closed and the ignition is turned on, and can only be deactivated by the driver latching his or her seat belt.},
	type = {patentus},
	number = {4849733A},
	author = {Conigliaro, Thomas S. and Coniliaro, Samuel J.},
	urldate = {2019-03-29},
	date = {1989-07-18},
	keywords = {circuit, driver, seat, vehicle, visible},
	file = {Fulltext PDF:/home/fabian/Zotero/storage/5TQX3JDB/Conigliaro and Coniliaro - 1989 - Seat belt indicator system.pdf:application/pdf}
}

@incollection{tan_brain-computer_2010,
	location = {London},
	title = {Brain-Computer Interfaces and Human-Computer Interaction},
	isbn = {978-1-84996-272-8},
	url = {https://doi.org/10.1007/978-1-84996-272-8_1},
	series = {Human-Computer Interaction Series},
	abstract = {Advances in cognitive neuroscience and brain imaging technologies have started to provide us with the ability to interface directly with the human brain. This ability is made possible through the use of sensors that can monitor some of the physical processes that occur within the brain that correspond with certain forms of thought. Researchers have used these technologies to build brain-computer interfaces ({BCIs}), communication systems that do not depend on the brain’s normal output pathways of peripheral nerves and muscles. In these systems, users explicitly manipulate their brain activity instead of using motor movements to produce signals that can be used to control computers or communication devices.Human-Computer Interaction ({HCI}) researchers explore possibilities that allow computers to use as many sensory channels as possible. Additionally, researchers have started to consider implicit forms of input, that is, input that is not explicitly performed to direct a computer to do something. Researchers attempt to infer information about user state and intent by observing their physiology, behavior, or the environment in which they operate. Using this information, systems can dynamically adapt themselves in order to support the user in the task at hand.{BCIs} are now mature enough that {HCI} researchers must add them to their tool belt when designing novel input techniques. In this introductory chapter to the book we present the novice reader with an overview of relevant aspects of {BCI} and {HCI}, so that hopefully they are inspired by the opportunities that remain.},
	pages = {3--19},
	booktitle = {Brain-Computer Interfaces: Applying our Minds to Human-Computer Interaction},
	publisher = {Springer London},
	author = {Tan, Desney and Nijholt, Anton},
	editor = {Tan, Desney S. and Nijholt, Anton},
	urldate = {2019-03-29},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-1-84996-272-8_1},
	keywords = {Brain Imaging, Brain Signal, Motor Movement, Near Infrared Spectroscopy, Novice Reader}
}

@article{mukhopadhyay_wearable_2015,
	title = {Wearable Sensors for Human Activity Monitoring: A Review},
	volume = {15},
	issn = {1530-437X},
	doi = {10.1109/JSEN.2014.2370945},
	shorttitle = {Wearable Sensors for Human Activity Monitoring},
	abstract = {An increase in world population along with a significant aging portion is forcing rapid rises in healthcare costs. The healthcare system is going through a transformation in which continuous monitoring of inhabitants is possible even without hospitalization. The advancement of sensing technologies, embedded systems, wireless communication technologies, nano technologies, and miniaturization makes it possible to develop smart systems to monitor activities of human beings continuously. Wearable sensors detect abnormal and/or unforeseen situations by monitoring physiological parameters along with other symptoms. Therefore, necessary help can be provided in times of dire need. This paper reviews the latest reported systems on activity monitoring of humans based on wearable sensors and issues to be addressed to tackle the challenges.},
	pages = {1321--1330},
	number = {3},
	journaltitle = {{IEEE} Sensors Journal},
	author = {Mukhopadhyay, S. C.},
	date = {2015-03},
	keywords = {activity monitoring, assisted living, Biomedical monitoring, biomedical transducers, body area networks, body sensor networks, embedded system, health care, healthcare cost system, hospitalization, human activity monitoring, intelligent sensors, Monitoring, nanosensors, nanotechnology, physiological parameter monitoring, physiological parameters monitoring, sensor networks, smart home, smart sensors, smart system, Temperature measurement, wearable sensor, wearable sensors, Wearable sensors, Wireless communication, wireless communication technology, wireless sensor networks, Wireless sensor networks},
	file = {IEEE Xplore Abstract Record:/home/fabian/Zotero/storage/NFYNEG8M/6974987.html:text/html}
}

@incollection{jacob_commentary_2003,
	location = {Amsterdam},
	title = {Commentary on Section 4 - Eye Tracking in Human-Computer Interaction and Usability Research: Ready to Deliver the Promises},
	isbn = {978-0-444-51020-4},
	url = {http://www.sciencedirect.com/science/article/pii/B9780444510204500311},
	shorttitle = {Commentary on Section 4 - Eye Tracking in Human-Computer Interaction and Usability Research},
	abstract = {This chapter discusses the application of eye movements to user interfaces, both for analyzing interfaces (measuring usability) and as an actual control medium within a human–computer dialogue. For usability analysis, the user's eye movements are recorded during system use and later analyzed retrospectively; however, the eye movements do not affect the interface in real time. As a direct control medium, the eye movements are obtained and used in real time as an input to the user–computer dialogue. The eye movements might be the sole input, typically for disabled users or hands-busy applications, or might be used as one of several inputs, combining with mouse, keyboard, sensors, or other devices. From the perspective of mainstream eye-movement research, human–computer interaction, together with related work in the broader field of communications and media research, appears as a new and very promising area of applied work. Both basic and applied work can profit from integration within a unified field of eye­-movement research. Application of eye tracking in human–computer interaction remains a very promising approach; its technological and market barriers are finally being reduced.},
	pages = {573--605},
	booktitle = {The Mind's Eye},
	publisher = {North-Holland},
	author = {Jacob, Robert J. K. and Karn, Keith S.},
	editor = {Hyönä, J. and Radach, R. and Deubel, H.},
	urldate = {2019-03-29},
	date = {2003-01-01},
	doi = {10.1016/B978-044451020-4/50031-1},
	file = {ScienceDirect Snapshot:/home/fabian/Zotero/storage/GDAUIZVF/B9780444510204500311.html:text/html}
}

@book{bishop_pattern_2006,
	title = {Pattern recognition and machine learning},
	publisher = {springer},
	author = {Bishop, Christopher M.},
	date = {2006},
	file = {Full Text:/home/fabian/Zotero/storage/PMCSV8GY/Bishop - 2006 - Pattern recognition and machine learning.pdf:application/pdf}
}

@incollection{koza_automated_1996,
	title = {Automated design of both the topology and sizing of analog electrical circuits using genetic programming},
	pages = {151--170},
	booktitle = {Artificial Intelligence in Design’96},
	publisher = {Springer},
	author = {Koza, John R. and Bennett, Forrest H. and Andre, David and Keane, Martin A.},
	date = {1996},
	file = {Full Text:/home/fabian/Zotero/storage/JQM85LVM/Koza et al. - 1996 - Automated design of both the topology and sizing o.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/M6XJ7BEA/978-94-009-0279-4_9.html:text/html}
}

@book{rogers_jr_theory_1987,
	title = {Theory of recursive functions and effective computability, paperback edition},
	publisher = {Cambridge: {MIT} Press},
	author = {Rogers Jr, Hartley},
	date = {1987}
}

@book{bishop_pattern_2006-1,
	title = {Pattern recognition and machine learning},
	publisher = {springer},
	author = {Bishop, Christopher M.},
	date = {2006},
	file = {Full Text:/home/fabian/Zotero/storage/G9VKIZ2V/Bishop - 2006 - Pattern recognition and machine learning.pdf:application/pdf}
}

@book{hinton_unsupervised_1999,
	title = {Unsupervised learning: foundations of neural computation},
	shorttitle = {Unsupervised learning},
	publisher = {{MIT} press},
	author = {Hinton, Geoffrey E. and Sejnowski, Terrence Joseph and Poggio, Tomaso A.},
	date = {1999},
	file = {Snapshot:/home/fabian/Zotero/storage/HCIR9A4W/books.html:text/html}
}

@article{russel_artificial_2010,
	title = {Artificial Intelligence: A Modern Approach Thrid Edition},
	shorttitle = {Artificial Intelligence},
	journaltitle = {Person Education, Boston Munich},
	author = {Russel, Stuart and Norvig, Peter},
	date = {2010}
}

@book{sutton_introduction_1998,
	title = {Introduction to reinforcement learning},
	volume = {135},
	publisher = {{MIT} press Cambridge},
	author = {Sutton, Richard S. and Barto, Andrew G.},
	date = {1998},
	file = {Full Text:/home/fabian/Zotero/storage/YSDFWR56/Sutton and Barto - 1998 - Introduction to reinforcement learning.pdf:application/pdf}
}

@article{wald_statistical_1950,
	title = {Statistical decision functions.},
	author = {Wald, Abraham},
	date = {1950},
	file = {Snapshot:/home/fabian/Zotero/storage/9YF38PBC/1951-01400-000.html:text/html}
}

@article{domingos_few_2012,
	title = {A few useful things to know about machine learning.},
	volume = {55},
	pages = {78--87},
	number = {10},
	journaltitle = {Commun. acm},
	author = {Domingos, Pedro M.},
	date = {2012},
	file = {Full Text:/home/fabian/Zotero/storage/REKG5EFL/Domingos - 2012 - A few useful things to know about machine learning.pdf:application/pdf}
}

@online{noauthor_machine_nodate,
	title = {machine learning overfitting - Google Scholar},
	url = {https://scholar.google.de/scholar?hl=en&as_sdt=0%2C5&q=machine+learning+overfitting&btnG=},
	urldate = {2019-03-29},
	file = {machine learning overfitting - Google Scholar:/home/fabian/Zotero/storage/FPU7ANQ7/scholar.html:text/html}
}

@book{friedman_elements_2001,
	title = {The elements of statistical learning},
	volume = {1},
	number = {10},
	publisher = {Springer series in statistics New York},
	author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
	date = {2001},
	file = {Full Text:/home/fabian/Zotero/storage/49GKIES2/Friedman et al. - 2001 - The elements of statistical learning.ps:application/postscript}
}

@article{hinton_reducing_2006,
	title = {Reducing the dimensionality of data with neural networks},
	volume = {313},
	pages = {504--507},
	number = {5786},
	journaltitle = {science},
	author = {Hinton, Geoffrey E. and Salakhutdinov, Ruslan R.},
	date = {2006},
	file = {Snapshot:/home/fabian/Zotero/storage/PYS9553M/504.html:text/html}
}

@article{silver_general_2018,
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	pages = {1140--1144},
	number = {6419},
	journaltitle = {Science},
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore},
	date = {2018},
	file = {Full Text:/home/fabian/Zotero/storage/LCGFWVLM/Silver et al. - 2018 - A general reinforcement learning algorithm that ma.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/K7XX4A9U/1140+.html:text/html}
}

@online{noauthor_scinapse_nodate,
	title = {Scinapse {\textbar} Academic search engine for paper},
	url = {https://scinapse.io},
	abstract = {sci-napse is the fastest search engine for scientific papers. sci-napse covers over 170m+ papers and 48k+ journals. Just try sci-napse, you can quickly find the scientific paper exactly you want.},
	titleaddon = {Scinapse},
	urldate = {2019-04-04},
	langid = {english},
	file = {Snapshot:/home/fabian/Zotero/storage/AICJBUSC/search.html:text/html}
}

@article{veltink_detection_1996,
	title = {Detection of static and dynamic activities using uniaxial accelerometers},
	volume = {4},
	pages = {375--385},
	number = {4},
	journaltitle = {{IEEE} Transactions on Rehabilitation Engineering},
	author = {Veltink, Peter H. and Bussmann, {HansB} J. and De Vries, Wiebe and Martens, {WimL} J. and Van Lummel, Rob C.},
	date = {1996},
	file = {Full Text:/home/fabian/Zotero/storage/XMJWG482/Veltink et al. - 1996 - Detection of static and dynamic activities using u.pdf:application/pdf}
}

@article{gers_learning_1999,
	title = {Learning to forget: Continual prediction with {LSTM}},
	shorttitle = {Learning to forget},
	author = {Gers, Felix A. and Schmidhuber, Jürgen and Cummins, Fred},
	date = {1999},
	file = {Full Text:/home/fabian/Zotero/storage/VTNB8WAH/Gers et al. - 1999 - Learning to forget Continual prediction with LSTM.pdf:application/pdf;Snapshot:/home/fabian/Zotero/storage/NUZT5HGZ/cp_19991218.html:text/html}
}

@article{keskar_improving_2017,
	title = {Improving Generalization Performance by Switching from Adam to {SGD}},
	url = {http://arxiv.org/abs/1712.07628},
	abstract = {Despite superior training outcomes, adaptive optimization methods such as Adam, Adagrad or {RMSprop} have been found to generalize poorly compared to Stochastic gradient descent ({SGD}). These methods tend to perform well in the initial portion of training but are outperformed by {SGD} at later stages of training. We investigate a hybrid strategy that begins training with an adaptive method and switches to {SGD} when appropriate. Concretely, we propose {SWATS}, a simple strategy which switches from Adam to {SGD} when a triggering condition is satisfied. The condition we propose relates to the projection of Adam steps on the gradient subspace. By design, the monitoring process for this condition adds very little overhead and does not increase the number of hyperparameters in the optimizer. We report experiments on several standard benchmarks such as: {ResNet}, {SENet}, {DenseNet} and {PyramidNet} for the {CIFAR}-10 and {CIFAR}-100 data sets, {ResNet} on the tiny-{ImageNet} data set and language modeling with recurrent networks on the {PTB} and {WT}2 data sets. The results show that our strategy is capable of closing the generalization gap between {SGD} and Adam on a majority of the tasks.},
	journaltitle = {{arXiv}:1712.07628 [cs, math]},
	author = {Keskar, Nitish Shirish and Socher, Richard},
	urldate = {2019-04-09},
	date = {2017-12-20},
	eprinttype = {arxiv},
	eprint = {1712.07628},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
	file = {arXiv\:1712.07628 PDF:/home/fabian/Zotero/storage/7LWKR4SZ/Keskar and Socher - 2017 - Improving Generalization Performance by Switching .pdf:application/pdf;arXiv.org Snapshot:/home/fabian/Zotero/storage/W8URMXNK/1712.html:text/html}
}

@inproceedings{sainath_convolutional_2015,
	title = {Convolutional, Long Short-Term Memory, fully connected Deep Neural Networks},
	doi = {10.1109/ICASSP.2015.7178838},
	abstract = {Both Convolutional Neural Networks ({CNNs}) and Long Short-Term Memory ({LSTM}) have shown improvements over Deep Neural Networks ({DNNs}) across a wide variety of speech recognition tasks. {CNNs}, {LSTMs} and {DNNs} are complementary in their modeling capabilities, as {CNNs} are good at reducing frequency variations, {LSTMs} are good at temporal modeling, and {DNNs} are appropriate for mapping features to a more separable space. In this paper, we take advantage of the complementarity of {CNNs}, {LSTMs} and {DNNs} by combining them into one unified architecture. We explore the proposed architecture, which we call {CLDNN}, on a variety of large vocabulary tasks, varying from 200 to 2,000 hours. We find that the {CLDNN} provides a 4-6\% relative improvement in {WER} over an {LSTM}, the strongest of the three individual models.},
	eventtitle = {2015 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	pages = {4580--4584},
	booktitle = {2015 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	author = {Sainath, T. N. and Vinyals, O. and Senior, A. and Sak, H.},
	date = {2015-04},
	keywords = {Hidden Markov models, Neural networks, Training, {CNN}, Context, convolutional memory, convolutional neural networks, {DNN}, frequency variations, fully connected deep neural networks, long short-term memory, {LSTM}, neural nets, Noise measurement, Speech, speech recognition, Speech recognition},
	file = {IEEE Xplore Abstract Record:/home/fabian/Zotero/storage/JGRWB7KZ/7178838.html:text/html}
}

@article{kingma_adam:_2014,
	title = {Adam: A Method for Stochastic Optimization},
	url = {http://arxiv.org/abs/1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the infinity norm.},
	journaltitle = {{arXiv}:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2019-05-06},
	date = {2014-12-22},
	eprinttype = {arxiv},
	eprint = {1412.6980},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv\:1412.6980 PDF:/home/fabian/Zotero/storage/HKFERZ3K/Kingma and Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/home/fabian/Zotero/storage/HCC9CPPM/1412.html:text/html}
}

@inproceedings{yang_deep_2015,
	title = {Deep convolutional neural networks on multichannel time series for human activity recognition},
	booktitle = {Twenty-Fourth International Joint Conference on Artificial Intelligence},
	author = {Yang, Jianbo and Nguyen, Minh Nhut and San, Phyo Phyo and Li, Xiao Li and Krishnaswamy, Shonali},
	date = {2015},
	file = {Snapshot:/home/fabian/Zotero/storage/AUQZDPJ3/10710.html:text/html}
}

@article{finkelstein_distinction_1999,
	title = {On the Distinction between Conscious and Unconscious States of Mind},
	volume = {36},
	issn = {0003-0481},
	url = {https://www.jstor.org/stable/20009956},
	pages = {79--100},
	number = {2},
	journaltitle = {American Philosophical Quarterly},
	author = {Finkelstein, David H.},
	urldate = {2019-05-31},
	date = {1999}
}

@article{tononi_consciousness_1998,
	title = {Consciousness and Complexity},
	volume = {282},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/282/5395/1846},
	doi = {10.1126/science.282.5395.1846},
	abstract = {Conventional approaches to understanding consciousness are generally concerned with the contribution of specific brain areas or groups of neurons. By contrast, it is considered here what kinds of neural processes can account for key properties of conscious experience. Applying measures of neural integration and complexity, together with an analysis of extensive neurological data, leads to a testable proposal—the dynamic core hypothesis—about the properties of the neural substrate of consciousness.},
	pages = {1846--1851},
	number = {5395},
	journaltitle = {Science},
	author = {Tononi, Giulio and Edelman, Gerald M.},
	urldate = {2019-05-31},
	date = {1998-12-04},
	langid = {english},
	pmid = {9836628},
	file = {Snapshot:/home/fabian/Zotero/storage/GFBYGQZD/1846.html:text/html;Submitted Version:/home/fabian/Zotero/storage/FL8VTTSF/Tononi and Edelman - 1998 - Consciousness and Complexity.pdf:application/pdf}
}

@article{arshavsky_cerebellum_1983,
	title = {The cerebellum and control of rhythmical movements},
	volume = {6},
	issn = {0166-2236, 1878-108X},
	url = {https://www.cell.com/trends/neurosciences/abstract/0166-2236(83)90191-1},
	doi = {10.1016/0166-2236(83)90191-1},
	pages = {417--422},
	journaltitle = {Trends in Neurosciences},
	shortjournal = {Trends in Neurosciences},
	author = {Arshavsky, Yu I. and Gelfand, I. M. and Orlovsky, G. N.},
	urldate = {2019-05-31},
	date = {1983-01-01},
	file = {Snapshot:/home/fabian/Zotero/storage/JQ2RFEJV/0166-2236(83)90191-1.html:text/html}
}

@article{granger_models_2007,
	title = {Models of thalamocortical system},
	volume = {2},
	pages = {1796},
	number = {11},
	journaltitle = {Scholarpedia},
	author = {Granger, Richard H. and Hearn, Robert A.},
	date = {2007},
	file = {Full Text:/home/fabian/Zotero/storage/2WX6C7Q3/Thalamo-cortical_model.html:text/html}
}

@inproceedings{verleysen_curse_2005,
	title = {The Curse of Dimensionality in Data Mining and Time Series Prediction},
	isbn = {978-3-540-32106-4},
	series = {Lecture Notes in Computer Science},
	abstract = {Modern data analysis tools have to work on high-dimensional data, whose components are not independently distributed. High-dimensional spaces show surprising, counter-intuitive geometrical properties that have a large influence on the performances of data analysis tools. Among these properties, the concentration of the norm phenomenon results in the fact that Euclidean norms and Gaussian kernels, both commonly used in models, become inappropriate in high-dimensional spaces. This papers presents alternative distance measures and kernels, together with geometrical methods to decrease the dimension of the space. The methodology is applied to a typical time series prediction example.},
	pages = {758--770},
	booktitle = {Computational Intelligence and Bioinspired Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Verleysen, Michel and François, Damien},
	editor = {Cabestany, Joan and Prieto, Alberto and Sandoval, Francisco},
	date = {2005},
	langid = {english},
	keywords = {Data Analysis Tool, Gaussian Kernel, Norm Phenomenon, Stock Market Index, Time Series Prediction}
}